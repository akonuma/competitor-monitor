import requests
import hashlib
import json
import os
import difflib
from datetime import datetime, timezone

# â”€â”€â”€ ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€ â”€â”€â”€
TARGET_URLS = json.loads(os.environ["TARGET_URLS"])
HASH_FILE   = "hashes.json"
CONTENT_DIR = "content_cache"  # ãƒšãƒ¼ã‚¸å†…å®¹ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
TEAMS_WEBHOOK = os.environ["TEAMS_WEBHOOK"]


def load_hashes() -> dict:
    """ãƒªãƒã‚¸ãƒˆãƒªä¸Šã®ãƒãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    if os.path.exists(HASH_FILE):
        with open(HASH_FILE) as f:
            return json.load(f)
    return {}


def save_hashes(hashes: dict):
    """ãƒãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€"""
    with open(HASH_FILE, "w") as f:
        json.dump(hashes, f, indent=2)


def get_page_content(url: str) -> str | None:
    """ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—"""
    try:
        resp = requests.get(url, timeout=15, headers={
            "User-Agent": "Mozilla/5.0 (compatible; SiteMonitorBot/1.0)"
        })
        resp.raise_for_status()
        return resp.text
    except Exception as e:
        print(f"[ERROR] {url} ã®å–å¾—ã«å¤±æ•—: {e}")
        return None


def get_content_hash(content: str) -> str:
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
    return hashlib.md5(content.encode('utf-8')).hexdigest()


def save_content(url: str, content: str):
    """ãƒšãƒ¼ã‚¸å†…å®¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    os.makedirs(CONTENT_DIR, exist_ok=True)
    filename = hashlib.md5(url.encode('utf-8')).hexdigest() + ".txt"
    filepath = os.path.join(CONTENT_DIR, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)


def load_content(url: str) -> str | None:
    """ä¿å­˜ã•ã‚ŒãŸãƒšãƒ¼ã‚¸å†…å®¹ã‚’èª­ã¿è¾¼ã‚€"""
    filename = hashlib.md5(url.encode('utf-8')).hexdigest() + ".txt"
    filepath = os.path.join(CONTENT_DIR, filename)
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            return f.read()
    return None


def get_diff_summary(old_content: str, new_content: str, max_lines: int = 10) -> str:
    """å¤‰æ›´ã®å·®åˆ†ã‚µãƒãƒªãƒ¼ã‚’å–å¾—ï¼ˆæœ€å¤§è¡Œæ•°åˆ¶é™ä»˜ãï¼‰"""
    old_lines = old_content.splitlines()
    new_lines = new_content.splitlines()
    
    diff = list(difflib.unified_diff(
        old_lines, 
        new_lines, 
        lineterm='',
        n=0  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡Œã‚’0ã«ã—ã¦å¤‰æ›´éƒ¨åˆ†ã®ã¿è¡¨ç¤º
    ))
    
    if not diff:
        return "å¤‰æ›´ãªã—"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆ@@ã§å§‹ã¾ã‚‹è¡Œï¼‰ã‚’é™¤å¤–ã—ã€å®Ÿéš›ã®å¤‰æ›´è¡Œã®ã¿æŠ½å‡º
    changes = []
    for line in diff[2:]:  # æœ€åˆã®2è¡Œã¯ãƒ•ã‚¡ã‚¤ãƒ«åãªã®ã§ã‚¹ã‚­ãƒƒãƒ—
        if line.startswith('---') or line.startswith('+++') or line.startswith('@@'):
            continue
        changes.append(line)
    
    # æœ€å¤§è¡Œæ•°ã¾ã§åˆ‡ã‚Šè©°ã‚
    if len(changes) > max_lines:
        changes = changes[:max_lines]
        changes.append(f"... (ä»– {len(diff) - max_lines} è¡Œã®å¤‰æ›´)")
    
    return "\n".join(changes) if changes else "è©³ç´°ãªå¤‰æ›´å†…å®¹ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"


def send_teams_alert(changed_urls: list[dict]):
    """å¤‰æ›´ã•ã‚ŒãŸURLã«ã¤ã„ã¦Teamsé€šçŸ¥ã‚’é€ä¿¡ï¼ˆå·®åˆ†ä»˜ãï¼‰"""
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")

    # å„URLã®æƒ…å ±ã‚’ sections ã¨ã—ã¦æ§‹ç¯‰
    sections = [{
        "activityTitle": "å¤‰æ›´æ¤œçŸ¥ã‚µãƒãƒªãƒ¼",
        "activitySubtitle": f"æ¤œçŸ¥æ™‚åˆ»: {now}",
        "text": f"**{len(changed_urls)}ä»¶ã®ã‚µã‚¤ãƒˆã§å¤‰æ›´ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸ**"
    }]
    
    for item in changed_urls:
        url = item["url"]
        diff_summary = item.get("diff", "å·®åˆ†æƒ…å ±ãªã—")
        
        sections.append({
            "activityTitle": f"ğŸ“ {url}",
            "text": f"```\n{diff_summary[:500]}\n```"  # æœ€å¤§500æ–‡å­—
        })

    payload = {
        "@type": "MessageCard",
        "@context": "https://schema.org/extensions",
        "summary": f"ç«¶åˆã‚µã‚¤ãƒˆæ›´æ–°æ¤œçŸ¥ ({len(changed_urls)}ä»¶)",
        "themeColor": "0078D4",
        "title": f"ğŸ”” ç«¶åˆã‚µã‚¤ãƒˆæ›´æ–°æ¤œçŸ¥ ({len(changed_urls)}ä»¶)",
        "sections": sections
    }

    try:
        resp = requests.post(TEAMS_WEBHOOK, json=payload, timeout=10)
        resp.raise_for_status()
        print(f"[OK] Teamsé€šçŸ¥é€ä¿¡å®Œäº†")
    except Exception as e:
        print(f"[ERROR] Teamsé€šçŸ¥é€ä¿¡å¤±æ•—: {e}")


def main():
    print(f"[START] {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')} ãƒã‚§ãƒƒã‚¯é–‹å§‹")

    hashes = load_hashes()
    changed = []

    for url in TARGET_URLS:
        current_content = get_page_content(url)
        if current_content is None:
            continue

        current_hash = get_content_hash(current_content)
        prev_hash = hashes.get(url)

        if prev_hash is None:
            # åˆå›ç™»éŒ²
            print(f"[NEW]     {url}")
            hashes[url] = current_hash
            save_content(url, current_content)
        elif current_hash != prev_hash:
            # å¤‰æ›´æ¤œçŸ¥
            print(f"[CHANGED] {url}")
            
            # å‰å›ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¦å·®åˆ†ã‚’è¨ˆç®—
            old_content = load_content(url)
            diff_summary = "å‰å›ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            
            if old_content:
                diff_summary = get_diff_summary(old_content, current_content, max_lines=15)
            
            changed.append({
                "url": url,
                "diff": diff_summary
            })
            
            # æ–°ã—ã„ãƒãƒƒã‚·ãƒ¥ã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¿å­˜
            hashes[url] = current_hash
            save_content(url, current_content)
        else:
            print(f"[OK]      {url}")

    # ãƒãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    save_hashes(hashes)

    # å¤‰æ›´ãŒã‚ã‚Œã°Teamsé€šçŸ¥
    if changed:
        send_teams_alert(changed)
    else:
        print("[INFO] å¤‰æ›´ãªã—")

    print("[END] ãƒã‚§ãƒƒã‚¯å®Œäº†")


if __name__ == "__main__":
    main()
