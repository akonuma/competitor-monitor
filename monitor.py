import requests
import hashlib
import json
import os
import difflib
import re
from datetime import datetime, timezone

# â”€â”€â”€ ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€ â”€â”€â”€
TARGET_URLS = json.loads(os.environ["TARGET_URLS"])
HASH_FILE   = "hashes.json"
CONTENT_DIR = "content_cache"
TEAMS_WEBHOOK = os.environ["TEAMS_WEBHOOK"]


def load_hashes() -> dict:
    """ãƒªãƒã‚¸ãƒˆãƒªä¸Šã®ãƒãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    if os.path.exists(HASH_FILE):
        with open(HASH_FILE) as f:
            return json.load(f)
    return {}


def save_hashes(hashes: dict):
    """ãƒãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€"""
    with open(HASH_FILE, "w") as f:
        json.dump(hashes, f, indent=2)


def normalize_content(content: str) -> str:
    """å‹•çš„ã«å¤‰ã‚ã‚‹è¦ç´ ã‚’æ­£è¦åŒ–ã—ã¦ç„¡è¦–ã™ã‚‹"""
    
    # 1. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç³»ã®å±æ€§ã‚’å‰Šé™¤
    patterns = [
        # WOVN ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¿ã‚¤ãƒ 
        r'data-wovnio-cache-time="[^"]*"',
        # ä¸€èˆ¬çš„ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        r'timestamp="[^"]*"',
        r'data-timestamp="[^"]*"',
        # æ—¥æ™‚ã‚’å«ã‚€ãƒ¡ã‚¿ã‚¿ã‚°
        r'content="[0-9]{12,14}\+[0-9]{4}"',
        # CSRFãƒˆãƒ¼ã‚¯ãƒ³ãªã©
        r'csrf[-_]token[^>]*value="[^"]*"',
        r'data-csrf="[^"]*"',
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        r'session[-_]id="[^"]*"',
        # ãƒ©ãƒ³ãƒ€ãƒ ãªID
        r'id="[a-f0-9]{32,}"',
        # Google Analytics ãªã©
        r'_ga=[^&\s"]*',
        r'gtm\.start=[^&\s"]*',
        # A/Bãƒ†ã‚¹ãƒˆãƒ»å®Ÿé¨“ID
        r'data-experiment[^>]*="[^"]*"',
        r'name="edge-experiment-treatments"\s+content="[^"]*"',
        r'data-testid="[^"]*"',
    ]
    
    normalized = content
    for pattern in patterns:
        normalized = re.sub(pattern, '', normalized, flags=re.IGNORECASE)
    
    # 2. é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«ã¾ã¨ã‚ã‚‹ï¼ˆæ­£è¦åŒ–ã®ãŸã‚ï¼‰
    normalized = re.sub(r'\s+', ' ', normalized)
    
    return normalized


def get_page_content(url: str) -> str | None:
    """ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—"""
    try:
        resp = requests.get(url, timeout=15, headers={
            "User-Agent": "Mozilla/5.0 (compatible; SiteMonitorBot/1.0)"
        })
        resp.raise_for_status()
        return resp.text
    except Exception as e:
        print(f"[ERROR] {url} ã®å–å¾—ã«å¤±æ•—: {e}")
        return None


def strip_html_tags(html: str) -> str:
    """HTML ã‚¿ã‚°ã‚’é™¤å»ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã®ã¿æŠ½å‡º"""
    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é™¤å»
    html = re.sub(r'<script[^>]*>.*?</script>', '', html, flags=re.DOTALL | re.IGNORECASE)
    html = re.sub(r'<style[^>]*>.*?</style>', '', html, flags=re.DOTALL | re.IGNORECASE)
    # HTML ã‚¿ã‚°ã‚’é™¤å»
    text = re.sub(r'<[^>]+>', '', html)
    # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«ã¾ã¨ã‚ã‚‹
    text = re.sub(r'\s+', ' ', text)
    # å„è¡Œã‚’ãƒˆãƒªãƒ 
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    return '\n'.join(lines)


def get_content_hash(content: str) -> str:
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆæ­£è¦åŒ–å¾Œï¼‰"""
    normalized = normalize_content(content)
    return hashlib.md5(normalized.encode('utf-8')).hexdigest()


def save_content(url: str, content: str):
    """ãƒšãƒ¼ã‚¸å†…å®¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    os.makedirs(CONTENT_DIR, exist_ok=True)
    filename = hashlib.md5(url.encode('utf-8')).hexdigest() + ".txt"
    filepath = os.path.join(CONTENT_DIR, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)


def load_content(url: str) -> str | None:
    """ä¿å­˜ã•ã‚ŒãŸãƒšãƒ¼ã‚¸å†…å®¹ã‚’èª­ã¿è¾¼ã‚€"""
    filename = hashlib.md5(url.encode('utf-8')).hexdigest() + ".txt"
    filepath = os.path.join(CONTENT_DIR, filename)
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            return f.read()
    return None


def get_diff_summary(old_content: str, new_content: str, max_lines: int = 10) -> str:
    """å¤‰æ›´ã®å·®åˆ†ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
    old_lines = old_content.splitlines()
    new_lines = new_content.splitlines()
    
    diff = list(difflib.unified_diff(
        old_lines, 
        new_lines, 
        lineterm='',
        n=0
    ))
    
    if not diff:
        return "å¤‰æ›´ãªã—"
    
    changes = []
    for line in diff[2:]:
        if line.startswith('---') or line.startswith('+++') or line.startswith('@@'):
            continue
        changes.append(line)
    
    if len(changes) > max_lines:
        changes = changes[:max_lines]
        changes.append(f"... (ä»– {len(diff) - max_lines} è¡Œ)")
    
    return '\n'.join(changes) if changes else "å·®åˆ†ãªã—"


def send_teams_alert(changed_urls: list[dict]):
    """å¤‰æ›´ã•ã‚ŒãŸURLã«ã¤ã„ã¦Teamsé€šçŸ¥ã‚’é€ä¿¡ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå·®åˆ† + HTMLå·®åˆ†ï¼‰"""
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")

    sections = [{
        "activityTitle": "å¤‰æ›´æ¤œçŸ¥ã‚µãƒãƒªãƒ¼",
        "activitySubtitle": f"æ¤œçŸ¥æ™‚åˆ»: {now}",
        "text": f"**{len(changed_urls)}ä»¶ã®ã‚µã‚¤ãƒˆã§å¤‰æ›´ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸ**"
    }]
    
    for item in changed_urls:
        url = item["url"]
        text_diff = item.get("text_diff", "å·®åˆ†æƒ…å ±ãªã—")
        html_diff = item.get("html_diff", "å·®åˆ†æƒ…å ±ãªã—")
        
        # ãƒ†ã‚­ã‚¹ãƒˆå·®åˆ†ï¼ˆèª­ã¿ã‚„ã™ã„ï¼‰
        sections.append({
            "activityTitle": f"ğŸ“ {url}",
            "activitySubtitle": "**ãƒ†ã‚­ã‚¹ãƒˆå·®åˆ†ï¼ˆèª­ã¿ã‚„ã™ã„è¡¨ç¤ºï¼‰**",
            "text": f"```\n{text_diff[:800]}\n```"
        })
        
        # HTMLå·®åˆ†ï¼ˆè©³ç´°ç¢ºèªç”¨ï¼‰
        sections.append({
            "activitySubtitle": "**HTMLå·®åˆ†ï¼ˆè©³ç´°ç¢ºèªç”¨ï¼‰**",
            "text": f"```html\n{html_diff[:500]}\n```"
        })

    payload = {
        "@type": "MessageCard",
        "@context": "https://schema.org/extensions",
        "summary": f"ç«¶åˆã‚µã‚¤ãƒˆæ›´æ–°æ¤œçŸ¥ ({len(changed_urls)}ä»¶)",
        "themeColor": "0078D4",
        "title": f"ğŸ”” ç«¶åˆã‚µã‚¤ãƒˆæ›´æ–°æ¤œçŸ¥ ({len(changed_urls)}ä»¶)",
        "sections": sections
    }

    try:
        resp = requests.post(TEAMS_WEBHOOK, json=payload, timeout=10)
        resp.raise_for_status()
        print(f"[OK] Teamsé€šçŸ¥é€ä¿¡å®Œäº†")
    except Exception as e:
        print(f"[ERROR] Teamsé€šçŸ¥é€ä¿¡å¤±æ•—: {e}")


def main():
    print(f"[START] {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')} ãƒã‚§ãƒƒã‚¯é–‹å§‹")

    hashes = load_hashes()
    changed = []

    for url in TARGET_URLS:
        current_content = get_page_content(url)
        if current_content is None:
            continue

        current_hash = get_content_hash(current_content)
        prev_hash = hashes.get(url)

        if prev_hash is None:
            # åˆå›ç™»éŒ²
            print(f"[NEW]     {url}")
            hashes[url] = current_hash
            save_content(url, current_content)
        elif current_hash != prev_hash:
            # å¤‰æ›´æ¤œçŸ¥
            print(f"[CHANGED] {url}")
            
            old_content = load_content(url)
            text_diff = "å‰å›ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            html_diff = "å‰å›ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            
            if old_content:
                # æ­£è¦åŒ–ã—ã¦æ¯”è¼ƒ
                old_normalized = normalize_content(old_content)
                new_normalized = normalize_content(current_content)
                
                # ãƒ†ã‚­ã‚¹ãƒˆå·®åˆ†ã‚’ä½œæˆ
                old_text = strip_html_tags(old_normalized)
                new_text = strip_html_tags(new_normalized)
                text_diff = get_diff_summary(old_text, new_text, max_lines=20)
                
                # HTMLå·®åˆ†ã‚’ä½œæˆ
                html_diff = get_diff_summary(old_normalized, new_normalized, max_lines=10)
            
            changed.append({
                "url": url,
                "text_diff": text_diff,
                "html_diff": html_diff
            })
            
            hashes[url] = current_hash
            save_content(url, current_content)
        else:
            print(f"[OK]      {url}")

    save_hashes(hashes)

    if changed:
        send_teams_alert(changed)
    else:
        print("[INFO] å¤‰æ›´ãªã—")

    print("[END] ãƒã‚§ãƒƒã‚¯å®Œäº†")


if __name__ == "__main__":
    main()
